{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "database = 'database.sqlite'\n",
    "conn = sqlite3.connect('../database/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league_id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>10260</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.50</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9825</td>\n",
       "      <td>8659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8472</td>\n",
       "      <td>8650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8654</td>\n",
       "      <td>8528</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>10252</td>\n",
       "      <td>8456</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8668</td>\n",
       "      <td>8655</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8549</td>\n",
       "      <td>8586</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8559</td>\n",
       "      <td>10194</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8667</td>\n",
       "      <td>9879</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>8455</td>\n",
       "      <td>8462</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>10260</td>\n",
       "      <td>8654</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>9825</td>\n",
       "      <td>8586</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>8549</td>\n",
       "      <td>8456</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>8559</td>\n",
       "      <td>8668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>8667</td>\n",
       "      <td>8455</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>10194</td>\n",
       "      <td>8472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>8650</td>\n",
       "      <td>8462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>10252</td>\n",
       "      <td>8655</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>10261</td>\n",
       "      <td>8659</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>10</td>\n",
       "      <td>9879</td>\n",
       "      <td>8528</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>10260</td>\n",
       "      <td>8667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8586</td>\n",
       "      <td>8650</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8668</td>\n",
       "      <td>9879</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8549</td>\n",
       "      <td>8654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>10261</td>\n",
       "      <td>10252</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8559</td>\n",
       "      <td>8456</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8659</td>\n",
       "      <td>8655</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8462</td>\n",
       "      <td>8528</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>10194</td>\n",
       "      <td>9825</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>8455</td>\n",
       "      <td>8472</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12107</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8302</td>\n",
       "      <td>8634</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8306</td>\n",
       "      <td>8372</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>9910</td>\n",
       "      <td>8305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8581</td>\n",
       "      <td>10205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12111</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>9906</td>\n",
       "      <td>8633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12112</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>9864</td>\n",
       "      <td>8560</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8315</td>\n",
       "      <td>10267</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12114</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>7878</td>\n",
       "      <td>9783</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8558</td>\n",
       "      <td>9869</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>8370</td>\n",
       "      <td>8603</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8634</td>\n",
       "      <td>8370</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8372</td>\n",
       "      <td>8302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8305</td>\n",
       "      <td>8306</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12120</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>10205</td>\n",
       "      <td>9910</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12121</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8633</td>\n",
       "      <td>8581</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.00</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12122</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8560</td>\n",
       "      <td>9906</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>10267</td>\n",
       "      <td>9864</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12124</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>9783</td>\n",
       "      <td>8315</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12125</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>9869</td>\n",
       "      <td>7878</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12126</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>8</td>\n",
       "      <td>8603</td>\n",
       "      <td>8558</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12127</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8634</td>\n",
       "      <td>8372</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>10.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8302</td>\n",
       "      <td>8305</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8306</td>\n",
       "      <td>10205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12130</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>9910</td>\n",
       "      <td>8633</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8581</td>\n",
       "      <td>8560</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12132</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>9906</td>\n",
       "      <td>10267</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>9864</td>\n",
       "      <td>9783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8315</td>\n",
       "      <td>9869</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>7878</td>\n",
       "      <td>8603</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>21518</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8370</td>\n",
       "      <td>8558</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12137 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       league_id     season  stage  home_team_api_id  away_team_api_id  \\\n",
       "0           1729  2008/2009      1             10260             10261   \n",
       "1           1729  2008/2009      1              9825              8659   \n",
       "2           1729  2008/2009      1              8472              8650   \n",
       "3           1729  2008/2009      1              8654              8528   \n",
       "4           1729  2008/2009      1             10252              8456   \n",
       "5           1729  2008/2009      1              8668              8655   \n",
       "6           1729  2008/2009      1              8549              8586   \n",
       "7           1729  2008/2009      1              8559             10194   \n",
       "8           1729  2008/2009      1              8667              9879   \n",
       "9           1729  2008/2009      1              8455              8462   \n",
       "10          1729  2008/2009     10             10260              8654   \n",
       "11          1729  2008/2009     10              9825              8586   \n",
       "12          1729  2008/2009     10              8549              8456   \n",
       "13          1729  2008/2009     10              8559              8668   \n",
       "14          1729  2008/2009     10              8667              8455   \n",
       "15          1729  2008/2009     10             10194              8472   \n",
       "16          1729  2008/2009     10              8650              8462   \n",
       "17          1729  2008/2009     10             10252              8655   \n",
       "18          1729  2008/2009     10             10261              8659   \n",
       "19          1729  2008/2009     10              9879              8528   \n",
       "20          1729  2008/2009     11             10260              8667   \n",
       "21          1729  2008/2009     11              8586              8650   \n",
       "22          1729  2008/2009     11              8668              9879   \n",
       "23          1729  2008/2009     11              8549              8654   \n",
       "24          1729  2008/2009     11             10261             10252   \n",
       "25          1729  2008/2009     11              8559              8456   \n",
       "26          1729  2008/2009     11              8659              8655   \n",
       "27          1729  2008/2009     11              8462              8528   \n",
       "28          1729  2008/2009     11             10194              9825   \n",
       "29          1729  2008/2009     11              8455              8472   \n",
       "...          ...        ...    ...               ...               ...   \n",
       "12107      21518  2015/2016      7              8302              8634   \n",
       "12108      21518  2015/2016      7              8306              8372   \n",
       "12109      21518  2015/2016      7              9910              8305   \n",
       "12110      21518  2015/2016      7              8581             10205   \n",
       "12111      21518  2015/2016      7              9906              8633   \n",
       "12112      21518  2015/2016      7              9864              8560   \n",
       "12113      21518  2015/2016      7              8315             10267   \n",
       "12114      21518  2015/2016      7              7878              9783   \n",
       "12115      21518  2015/2016      7              8558              9869   \n",
       "12116      21518  2015/2016      7              8370              8603   \n",
       "12117      21518  2015/2016      8              8634              8370   \n",
       "12118      21518  2015/2016      8              8372              8302   \n",
       "12119      21518  2015/2016      8              8305              8306   \n",
       "12120      21518  2015/2016      8             10205              9910   \n",
       "12121      21518  2015/2016      8              8633              8581   \n",
       "12122      21518  2015/2016      8              8560              9906   \n",
       "12123      21518  2015/2016      8             10267              9864   \n",
       "12124      21518  2015/2016      8              9783              8315   \n",
       "12125      21518  2015/2016      8              9869              7878   \n",
       "12126      21518  2015/2016      8              8603              8558   \n",
       "12127      21518  2015/2016      9              8634              8372   \n",
       "12128      21518  2015/2016      9              8302              8305   \n",
       "12129      21518  2015/2016      9              8306             10205   \n",
       "12130      21518  2015/2016      9              9910              8633   \n",
       "12131      21518  2015/2016      9              8581              8560   \n",
       "12132      21518  2015/2016      9              9906             10267   \n",
       "12133      21518  2015/2016      9              9864              9783   \n",
       "12134      21518  2015/2016      9              8315              9869   \n",
       "12135      21518  2015/2016      9              7878              8603   \n",
       "12136      21518  2015/2016      9              8370              8558   \n",
       "\n",
       "       home_team_goal  away_team_goal  B365H  B365D  B365A  \n",
       "0                   1               1   1.29   5.50  11.00  \n",
       "1                   1               0   1.20   6.50  15.00  \n",
       "2                   0               1   5.50   3.60   1.67  \n",
       "3                   2               1   1.91   3.40   4.20  \n",
       "4                   4               2   1.91   3.40   4.33  \n",
       "5                   2               3   2.00   3.30   4.00  \n",
       "6                   2               1   3.20   3.40   2.25  \n",
       "7                   3               1   1.83   3.50   4.50  \n",
       "8                   2               1   2.60   3.20   2.80  \n",
       "9                   4               0   1.33   5.00  10.00  \n",
       "10                  2               0   1.20   6.00  19.00  \n",
       "11                  4               4   1.44   4.50   7.50  \n",
       "12                  2               0   2.88   3.30   2.50  \n",
       "13                  0               1   2.60   3.30   2.75  \n",
       "14                  0               3   8.00   4.33   1.44  \n",
       "15                  1               0   2.60   3.30   2.75  \n",
       "16                  1               0   1.33   5.00  10.00  \n",
       "17                  3               2   1.67   3.75   5.50  \n",
       "18                  2               1   1.83   3.50   4.50  \n",
       "19                  2               0   2.38   3.30   3.00  \n",
       "20                  4               3   1.17   7.00  17.00  \n",
       "21                  2               1   3.50   3.30   2.10  \n",
       "22                  1               0   1.67   3.75   5.50  \n",
       "23                  1               1   2.00   3.30   4.00  \n",
       "24                  2               0   3.00   3.30   2.38  \n",
       "25                  2               0   3.00   3.30   2.38  \n",
       "26                  2               2   2.50   3.30   2.88  \n",
       "27                  1               2   1.91   3.40   4.20  \n",
       "28                  2               1   8.00   4.50   1.40  \n",
       "29                  5               0   1.17   6.50  21.00  \n",
       "...               ...             ...    ...    ...    ...  \n",
       "12107               2               1   4.00   3.60   1.91  \n",
       "12108               0               2   2.10   3.30   3.75  \n",
       "12109               0               0   1.44   4.50   7.50  \n",
       "12110               1               0   4.33   3.40   1.91  \n",
       "12111               1               1   3.20   3.30   2.30  \n",
       "12112               3               1   2.38   3.10   3.30  \n",
       "12113               3               1   2.30   3.30   3.20  \n",
       "12114               1               1   2.60   3.20   2.80  \n",
       "12115               1               2   2.00   3.30   4.00  \n",
       "12116               0               2   2.20   3.50   3.20  \n",
       "12117               5               2   1.14   9.00  15.00  \n",
       "12118               1               1   3.60   3.40   2.10  \n",
       "12119               4               0   2.15   3.20   3.60  \n",
       "12120               1               2   2.00   3.50   3.75  \n",
       "12121               3               0   1.08  12.00  23.00  \n",
       "12122               0               2   4.00   3.20   2.05  \n",
       "12123               3               0   1.62   3.75   6.00  \n",
       "12124               2               2   2.70   3.10   2.80  \n",
       "12125               3               3   2.00   3.20   4.20  \n",
       "12126               1               3   2.00   3.30   4.00  \n",
       "12127               3               1   1.11  10.00  19.00  \n",
       "12128               5               0   1.44   4.33   8.00  \n",
       "12129               0               0   3.50   3.25   2.20  \n",
       "12130               1               3   3.80   3.80   1.91  \n",
       "12131               0               4   2.63   3.20   2.80  \n",
       "12132               2               1   1.57   3.80   6.50  \n",
       "12133               2               0   2.25   3.25   3.40  \n",
       "12134               3               0   1.53   4.00   7.00  \n",
       "12135               1               1   2.30   3.25   3.25  \n",
       "12136               3               0   2.20   3.40   3.20  \n",
       "\n",
       "[12137 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"select league_id,season,stage,home_team_api_id,away_team_api_id,home_team_goal,away_team_goal,B365H,B365D,B365A from Match where league_id=21518 or league_id= 1729 or league_id=4769 or league_id=10257\"\"\"                  \n",
    "\n",
    "data = pd.read_sql(sql,conn)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Converting season values\n",
    "\n",
    "def change_season(match):\n",
    "    if match['season'] =='2008/2009':\n",
    "        return 0\n",
    "    elif match['season'] =='2009/2010':\n",
    "        return 1\n",
    "    elif match['season'] =='2010/2011':\n",
    "        return 2\n",
    "    elif match['season'] =='2011/2012':\n",
    "        return 3\n",
    "    elif match['season'] =='2012/2013':\n",
    "        return 4\n",
    "    elif match['season'] =='2013/2014':\n",
    "        return 5\n",
    "    elif match['season'] =='2014/2015':\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "    \n",
    "data['season']=data.apply(change_season, axis=1) \n",
    "\n",
    "#Classifing Match output\n",
    "def determine_home_result(match):\n",
    "    if match['home_team_goal'] > match['away_team_goal']:\n",
    "        return 1\n",
    "    elif match['home_team_goal'] < match['away_team_goal']:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "data['Output']=data.apply(determine_home_result, axis=1)\n",
    "\n",
    "data= data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#função SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "train = data[data['season']<=5]\n",
    "val = data[data['season']==6]\n",
    "test = data[data['season']==7]\n",
    "\n",
    "ft=['league_id','season','stage','home_team_api_id','away_team_api_id','B365H','B365D','B365A']\n",
    "out=['Output']\n",
    "def SVM_validation(kernel,C,train,val,ft,out):\n",
    "    best=[]\n",
    "    sc_max=-10000\n",
    "    print kernel\n",
    "    print C\n",
    "    print ft\n",
    "    print out\n",
    "    for kernel_type in kernel:\n",
    "        print kernel_type\n",
    "        for cv in C:\n",
    "            print cv\n",
    "            clf = SVC(C=cv,kernel=kernel_type)\n",
    "            clf.fit(train[ft],train[out])\n",
    "            score = log_loss(val[out], clf.predict(val[ft]))\n",
    "            if score>sc_max:\n",
    "                best=clf\n",
    "                sc_max=score\n",
    "    return best\n",
    "\n",
    "c = range(1,2)\n",
    "kernel=['poly', 'rbf', 'sigmoid']\n",
    "#svm = SVM_validation (kernel,c,train,val,ft,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.001\n",
      "lbfgs 0.01\n",
      "lbfgs 0.1\n",
      "lbfgs 1\n",
      "lbfgs 10\n",
      "lbfgs 100\n",
      "lbfgs 1000\n",
      "liblinear 0.001\n",
      "liblinear 0.01\n",
      "liblinear 0.1\n",
      "liblinear 1\n",
      "liblinear 10\n",
      "liblinear 100\n",
      "liblinear 1000\n",
      "sag 0.001\n",
      "sag 0.01\n",
      "sag 0.1\n",
      "sag 1\n",
      "sag 10\n",
      "sag 100\n",
      "sag 1000\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=10000, multi_class='ovr',\n",
      "          n_jobs=-1, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Função logreg\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def logreg_validation(C,solver,train,val,ft,out):\n",
    "    sc_max = -10000\n",
    "    best=[]\n",
    "    for s in solver:\n",
    "        for cv in C:\n",
    "            print s,cv\n",
    "            lg = linear_model.LogisticRegression(C=cv,solver=s,n_jobs=-1,max_iter=100000)\n",
    "            lg.fit(train[ft],train[out])\n",
    "            score = f1_score(val[out], lg.predict(val[ft]),average='weighted')\n",
    "            if score>sc_max:\n",
    "                best=lg\n",
    "                sc_max=score\n",
    "    return best\n",
    "\n",
    "C= [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "logreg=logreg_validation(C,solver,train,val,ft,out)\n",
    "print logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.423700119474\n",
      "0.372542829717\n",
      "0.504279131007\n"
     ]
    }
   ],
   "source": [
    "print f1_score(test[out],logreg.predict(test[ft]),average='weighted')\n",
    "print f1_score(test[out],logreg.predict(test[ft]),average='macro')\n",
    "print f1_score(test[out],logreg.predict(test[ft]),average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/ipykernel/__main__.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439711366681\n",
      "0.400354070005\n",
      "0.479262672811\n",
      "Gaussian NB\n",
      "0.405746672326\n",
      "0.362069633601\n",
      "0.470704410797\n",
      "GradientBoosting NB\n",
      "0.463657947679\n",
      "0.426453086191\n",
      "0.499012508229\n"
     ]
    }
   ],
   "source": [
    "#Função RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def rf_validation(n_estimators,train,val,ft,out):\n",
    "    sc_max = -10000\n",
    "    best=[]\n",
    "    for n in n_estimators:\n",
    "        rf = RandomForestClassifier(n_estimators=n,n_jobs=-1)\n",
    "        rf.fit(train[ft],train[out])\n",
    "        score = f1_score(val[out], rf.predict(val[ft]),average='weighted')\n",
    "        if score>sc_max:\n",
    "            best=rf\n",
    "            sc_max=score\n",
    "    return best\n",
    "\n",
    "n = range(100,1000,50)\n",
    "\n",
    "rf= rf_validation(n,train,val,ft,out)\n",
    "\n",
    "print f1_score(test[out],rf.predict(test[ft]),average='weighted')\n",
    "print f1_score(test[out],rf.predict(test[ft]),average='macro')\n",
    "print f1_score(test[out],rf.predict(test[ft]),average='micro')\n",
    "\n",
    "#Função Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def nb_validation(train,val,ft,out):\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(train[ft],train[out])\n",
    "    return nb\n",
    "\n",
    "nb= nb_validation(train,val,ft,out)\n",
    "print \"Gaussian NB\"\n",
    "print f1_score(test[out],nb.predict(test[ft]),average='weighted')\n",
    "print f1_score(test[out],nb.predict(test[ft]),average='macro')\n",
    "print f1_score(test[out],nb.predict(test[ft]),average='micro')\n",
    "#Gradient Boosting\n",
    "def gb_validation(learning_rate,n_estimators,train,val,ft,out):\n",
    "    sc_max = -10000\n",
    "    best=[]\n",
    "    for n in n_estimators:\n",
    "        for lr in learning_rate:\n",
    "            gb = GradientBoostingClassifier(learning_rate=lr,n_estimators=n)\n",
    "            gb.fit(train[ft],train[out])\n",
    "            score = f1_score(val[out], gb.predict(val[ft]),average='weighted')\n",
    "            if score>sc_max:\n",
    "                best=gb\n",
    "                sc_max=score\n",
    "    return best\n",
    "\n",
    "lr= [0.0001, 0.001, 0.01, 0.1]\n",
    "gb= gb_validation(lr,n,train,val,ft,out)\n",
    "\n",
    "print \"GradientBoosting NB\"\n",
    "print f1_score(test[out],gb.predict(test[ft]),average='weighted')\n",
    "print f1_score(test[out],gb.predict(test[ft]),average='macro')\n",
    "print f1_score(test[out],gb.predict(test[ft]),average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tF1Score\t      F1 macro\t    F1 micro\n",
      "Naive       0.273428099737 0.205104831358 0.444371296906\n",
      "LogReg      0.423700119474 0.372542829717 0.504279131007\n",
      "Naive Bayes 0.405746672326 0.362069633601 0.470704410797\n",
      "Random F.   0.439711366681 0.400354070005 0.479262672811\n",
      "G. Boost.   0.463657947679 0.426453086191 0.499012508229\n"
     ]
    }
   ],
   "source": [
    "#GaussianProcess\n",
    "ynaive = [train['Output'].mode()[0]]*len(test)\n",
    "naive = f1_score(test[out],ynaive,average='weighted')\n",
    "#print \"LogReg\n",
    "print \"\\t\\tF1Score\\t\",\"      F1 macro\\t\",\"    F1 micro\"\n",
    "print \"Naive      \", naive,f1_score(test[out],ynaive,average='macro'),f1_score(test[out],ynaive,average='micro')\n",
    "print \"LogReg     \", f1_score(test[out],logreg.predict(test[ft]),average='weighted'),f1_score(test[out],logreg.predict(test[ft]),average='macro'),f1_score(test[out],logreg.predict(test[ft]),average='micro')\n",
    "print \"Naive Bayes\", f1_score(test[out],nb.predict(test[ft]),average='weighted'),f1_score(test[out],nb.predict(test[ft]),average='macro'),f1_score(test[out],nb.predict(test[ft]),average='micro')\n",
    "print \"Random F.  \", f1_score(test[out],rf.predict(test[ft]),average='weighted'),f1_score(test[out],rf.predict(test[ft]),average='macro'),f1_score(test[out],rf.predict(test[ft]),average='micro')\n",
    "print \"G. Boost.  \", f1_score(test[out],gb.predict(test[ft]),average='weighted'),f1_score(test[out],gb.predict(test[ft]),average='macro'),f1_score(test[out],gb.predict(test[ft]),average='micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def IDtoStr(league_id):\n",
    "    league_id = int(league_id)\n",
    "    if league_id == 1729 : \n",
    "        return \"Liga Inglesa\"\n",
    "    elif league_id == 4769 : \n",
    "        return \"Liga Francesa\"\n",
    "    elif league_id == 7809 : \n",
    "        return \"Liga Alema\"\n",
    "    elif league_id == 10257 : \n",
    "        return \"Liga Italiana\"\n",
    "    elif league_id == 21518 : \n",
    "        return \"Liga Espanhola\"\n",
    "    else:\n",
    "        return \"Liga Portuguesa\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.24647806e+02,   5.19598396e+02,   9.52323327e+00,\n",
       "         1.26433404e+03,   6.59130801e+01,   5.28868962e+02,\n",
       "         2.05073410e+01,   8.96124627e+01,   1.04726740e+02,\n",
       "         4.89243058e+00,   2.56966163e+01,   7.72855776e+01,\n",
       "         8.58746579e+01,   2.63043078e+02,   3.94795584e+02,\n",
       "         3.50156779e+02,   1.38041559e+02,   7.03810182e+00,\n",
       "         2.13813299e+02,   2.81199015e+02,   2.42380619e+01,\n",
       "         6.79514134e+02,   7.24329400e+01,   2.03094393e+02,\n",
       "         1.55640608e+01,   5.17560604e+01,   3.38012144e+01,\n",
       "         1.53326883e+00,   2.65480515e+01,   7.46690427e+01,\n",
       "         9.58395302e+01,   1.17771851e+02,   1.84601365e+02,\n",
       "         1.64124599e+02,   6.16613863e+01,   1.61085149e+01,\n",
       "         1.25465024e+02,   9.38709509e+01,   1.93580454e+00,\n",
       "         2.58334732e+02,   5.11931009e+01,   9.89158466e+01,\n",
       "         2.02527607e+01,   2.05058732e+01,   2.48734744e+01,\n",
       "         1.35131653e-01,   4.48562719e+00,   1.19251066e+01,\n",
       "         1.27993827e+01,   7.72137605e+01,   7.83830259e+01,\n",
       "         5.76605833e+01,   5.40105603e+01,   3.44821014e+00,\n",
       "         4.48909373e+01,   3.75991507e+01,   6.37220277e+00,\n",
       "         1.28237160e+02,   5.68970005e+01,   2.93765628e+01,\n",
       "         1.27499304e+01,   9.55002612e+00,   8.64035894e+00,\n",
       "         2.91972328e-01,   6.39078451e+00,   1.64865327e+01,\n",
       "         1.81578104e+01,   2.82374252e+01,   3.55227188e+01,\n",
       "         2.71969684e+01,   2.07073000e+01,   1.28434462e+01,\n",
       "         7.20969773e+02,   4.46162157e+02,   9.27863829e+00,\n",
       "         1.61284961e+03,   6.63996714e+01,   3.99421673e+02,\n",
       "         2.17688530e+01,   6.09102932e+01,   1.54926236e+02,\n",
       "         3.65335393e+00,   3.56247965e+01,   8.35847846e+01,\n",
       "         1.16387909e+02,   4.11069069e+02,   2.96835361e+02,\n",
       "         2.47729549e+02,   2.55169228e+02,   6.33276071e+00,\n",
       "         3.88638402e+02,   1.93229739e+02,   2.15507259e+00,\n",
       "         6.48007825e+02,   5.56650816e+01,   2.04620336e+02,\n",
       "         2.27262460e+01,   2.68211353e+01,   9.01814629e+01,\n",
       "         6.97807116e+00,   5.84007027e+00,   2.13915184e+01,\n",
       "         1.55672616e+01,   2.35069234e+02,   1.53011402e+02,\n",
       "         1.11551272e+02,   1.58163138e+02,   1.50839682e+00,\n",
       "         1.58196068e+02,   1.03307693e+02,   1.13148631e+01,\n",
       "         2.91867547e+02,   5.83982099e+01,   1.22634821e+02,\n",
       "         2.44296824e+01,   2.47263001e+01,   2.07410041e+01,\n",
       "         1.50538698e+00,   5.70902540e+00,   8.69730149e+00,\n",
       "         8.50937714e+00,   1.01843594e+02,   5.59640503e+01,\n",
       "         5.32365857e+01,   5.80096679e+01,   4.09607308e+00,\n",
       "         7.99525685e+01,   4.44765429e+01,   1.11331841e+00,\n",
       "         9.70028595e+01,   4.93862997e+01,   6.14531405e+01,\n",
       "         2.39503189e+01,   1.49218907e+01,   9.56806839e+00,\n",
       "         7.58632879e-01,   1.09041302e-01,   1.04542588e+00,\n",
       "         7.27732019e-01,   6.65694222e+01,   2.93004126e+01,\n",
       "         2.44084211e+01,   3.86618176e+01,   6.76624038e-01,\n",
       "         4.27570689e+02,   6.70658213e+02,   5.72276675e+02,\n",
       "         8.23335652e+02,   1.57718551e+02,   1.59636396e+02,\n",
       "         2.02769027e+02,   2.45502482e+02,   9.38586729e-01,\n",
       "         1.89503518e+00,   5.16984582e+00,   9.93495744e+02,\n",
       "         8.83660845e+01,   2.22764630e+03])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured = pd.read_csv('dados2.csv')\n",
    "featured['Output']=featured.apply(determine_home_result, axis=1)\n",
    "featured['season']=featured.apply(change_season, axis=1) \n",
    "\n",
    "featured= featured.dropna()\n",
    "\n",
    "import pandasql as pdsql\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "\n",
    "#data = pysql(\"Select * from data where league_id=21518 or league_id= 1729 or league_id=4769 or league_id=10257\")\n",
    "\n",
    "featured = pysql(\"Select * from featured where league_id=21518 or league_id= 1729 or league_id=4769 or league_id=10257\")\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "ft=[u'hg_V', u'hg_D', u'hg_E', u'hg_GF', u'hg_AVG_GF', u'hg_GS',\n",
    "       u'hg_AVG_GS', u'hg_J1GS', u'hg_J1GF', u'hg_BTTS', u'hg_Over2',\n",
    "       u'hg_Over3', u'hg_Over4', u'hg_WinningCleanSheet', u'hg_LosingFS',\n",
    "       u'hg_FailedScore', u'hg_CleanSheet', u'hg_AVG_GOALS', u'hgc_V',\n",
    "       u'hgc_D', u'hgc_E', u'hgc_GF', u'hgc_AVG_GF', u'hgc_GS',\n",
    "       u'hgc_AVG_GS', u'hgc_J1GS', u'hgc_J1GF', u'hgc_BTTS', u'hgc_Over2',\n",
    "       u'hgc_Over3', u'hgc_Over4', u'hgc_WinningCleanSheet',\n",
    "       u'hgc_LosingFS', u'hgc_FailedScore', u'hgc_CleanSheet',\n",
    "       u'hgc_AVG_GOALS', u'hl_V', u'hl_D', u'hl_E', u'hl_GF', u'hl_AVG_GF',\n",
    "       u'hl_GS', u'hl_AVG_GS', u'hl_J1GS', u'hl_J1GF', u'hl_BTTS',\n",
    "       u'hl_Over2', u'hl_Over3', u'hl_Over4', u'hl_WinningCleanSheet',\n",
    "       u'hl_LosingFS', u'hl_FailedScore', u'hl_CleanSheet',\n",
    "       u'hl_AVG_GOALS', u'hlc_V', u'hlc_D', u'hlc_E', u'hlc_GF',\n",
    "       u'hlc_AVG_GF', u'hlc_GS', u'hlc_AVG_GS', u'hlc_J1GS', u'hlc_J1GF',\n",
    "       u'hlc_BTTS', u'hlc_Over2', u'hlc_Over3', u'hlc_Over4',\n",
    "       u'hlc_WinningCleanSheet', u'hlc_LosingFS', u'hlc_FailedScore',\n",
    "       u'hlc_CleanSheet', u'hlc_AVG_GOALS', u'ag_V', u'ag_D', u'ag_E',\n",
    "       u'ag_GF', u'ag_AVG_GF', u'ag_GS', u'ag_AVG_GS', u'ag_J1GS',\n",
    "       u'ag_J1GF', u'ag_BTTS', u'ag_Over2', u'ag_Over3', u'ag_Over4',\n",
    "       u'ag_WinningCleanSheet', u'ag_LosingFS', u'ag_FailedScore',\n",
    "       u'ag_CleanSheet', u'ag_AVG_GOALS', u'agc_V', u'agc_D', u'agc_E',\n",
    "       u'agc_GF', u'agc_AVG_GF', u'agc_GS', u'agc_AVG_GS', u'agc_J1GS',\n",
    "       u'agc_J1GF', u'agc_BTTS', u'agc_Over2', u'agc_Over3', u'agc_Over4',\n",
    "       u'agc_WinningCleanSheet', u'agc_LosingFS', u'agc_FailedScore',\n",
    "       u'agc_CleanSheet', u'agc_AVG_GOALS', u'al_V', u'al_D', u'al_E',\n",
    "       u'al_GF', u'al_AVG_GF', u'al_GS', u'al_AVG_GS', u'al_J1GS',\n",
    "       u'al_J1GF', u'al_BTTS', u'al_Over2', u'al_Over3', u'al_Over4',\n",
    "       u'al_WinningCleanSheet', u'al_LosingFS', u'al_FailedScore',\n",
    "       u'al_CleanSheet', u'al_AVG_GOALS', u'alc_V', u'alc_D', u'alc_E',\n",
    "       u'alc_GF', u'alc_AVG_GF', u'alc_GS', u'alc_AVG_GS', u'alc_J1GS',\n",
    "       u'alc_J1GF', u'alc_BTTS', u'alc_Over2', u'alc_Over3', u'alc_Over4',\n",
    "       u'alc_WinningCleanSheet', u'alc_LosingFS', u'alc_FailedScore',\n",
    "       u'alc_CleanSheet', u'alc_AVG_GOALS', u'ga_rank_def', u'ga_rank_atk',\n",
    "       u'gh_rank_def', u'gh_rank_atk', u'la_rank_def', u'la_rank_atk',\n",
    "       u'lh_rank_def', u'lh_rank_atk', u'a_date', u'h_date', u'stage','B365H','B365D','B365A']\n",
    "\n",
    "\n",
    "ft_rank,pvalue = chi2(ft_train[ft],ft_train[out])\n",
    "ft_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(157, 2227.646296547724),\n",
       " (75, 1612.8496062112019),\n",
       " (3, 1264.3340444561754),\n",
       " (155, 993.49574355211303),\n",
       " (147, 823.33565245790498),\n",
       " (72, 720.96977349543215),\n",
       " (21, 679.51413355271461),\n",
       " (145, 670.65821320455086),\n",
       " (93, 648.00782463013081),\n",
       " (146, 572.27667481086803),\n",
       " (5, 528.86896196575435),\n",
       " (0, 524.64780622404032),\n",
       " (1, 519.59839616371482),\n",
       " (73, 446.1621567911011),\n",
       " (144, 427.57068859312915),\n",
       " (85, 411.06906945344826),\n",
       " (77, 399.42167264736304),\n",
       " (14, 394.79558447609327),\n",
       " (90, 388.63840234894411),\n",
       " (15, 350.15677875820347),\n",
       " (86, 296.83536099061507),\n",
       " (111, 291.86754653224205),\n",
       " (19, 281.19901470504828),\n",
       " (13, 263.04307828995445),\n",
       " (39, 258.33473207557358),\n",
       " (88, 255.16922848404576),\n",
       " (87, 247.72954945150201),\n",
       " (151, 245.50248222661128),\n",
       " (103, 235.06923447387837),\n",
       " (18, 213.81329894808033),\n",
       " (95, 204.62033554437451),\n",
       " (23, 203.09439292065861),\n",
       " (150, 202.76902717394375),\n",
       " (91, 193.22973879331408),\n",
       " (32, 184.60136514291884),\n",
       " (33, 164.12459900736957),\n",
       " (149, 159.63639602236208),\n",
       " (108, 158.19606769149746),\n",
       " (106, 158.16313797586361),\n",
       " (148, 157.71855142435479),\n",
       " (80, 154.92623636804353),\n",
       " (104, 153.01140210761443),\n",
       " (16, 138.04155908120268),\n",
       " (57, 128.23715969346972),\n",
       " (36, 125.46502374100032),\n",
       " (113, 122.63482112043133),\n",
       " (31, 117.7718508999471),\n",
       " (84, 116.38790933098403),\n",
       " (105, 111.55127204773234),\n",
       " (8, 104.72674019698182),\n",
       " (109, 103.30769338405962),\n",
       " (121, 101.84359441558128)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank={}\n",
    "i=0\n",
    "for v in ft_rank:\n",
    "    if v>=100:\n",
    "        rank[i]=v\n",
    "    i=i+1\n",
    "\n",
    "import operator\n",
    "\n",
    "sorted_x = sorted(rank.items(), key=operator.itemgetter(1),reverse=True)\n",
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B365A 2227.64629655 0.0\n",
      "ag_GF 1612.84960621 0.0\n",
      "hg_GF 1264.33404446 2.84021100025e-275\n",
      "B365H 993.495743552 1.84136714748e-216\n",
      "gh_rank_atk 823.335652458 1.64034308312e-179\n",
      "ag_V 720.969773495 2.77589398576e-157\n",
      "hgc_GF 679.514133553 2.78856461005e-148\n",
      "ga_rank_atk 670.658213205 2.3357124792e-146\n",
      "agc_GF 648.00782463 1.93592606217e-141\n",
      "gh_rank_def 572.276674811 5.39136833838e-125\n",
      "hg_GS 528.868961966 1.43735513281e-115\n",
      "hg_V 524.647806224 1.18625049628e-114\n",
      "hg_D 519.598396164 1.48129606843e-113\n",
      "ag_D 446.162156791 1.30953959976e-97\n",
      "ga_rank_def 427.570688593 1.42627956602e-93\n",
      "ag_WinningCleanSheet 411.069069453 5.46368594088e-90\n",
      "ag_GS 399.421672647 1.84793124382e-87\n",
      "hg_LosingFS 394.795584476 1.86736016948e-86\n",
      "agc_V 388.638402349 4.05735681179e-85\n",
      "hg_FailedScore 350.156778758 9.21343533663e-77\n",
      "ag_LosingFS 296.835360991 3.49156670924e-65\n",
      "al_GF 291.867546532 4.18569469047e-64\n",
      "hgc_D 281.199014705 8.67780323492e-62\n",
      "hg_WinningCleanSheet 263.04307829 7.60188504426e-58\n",
      "hl_GF 258.334732076 8.00434294795e-57\n",
      "ag_CleanSheet 255.169228484 3.89678153753e-56\n",
      "ag_FailedScore 247.729549452 1.60772525675e-54\n",
      "lh_rank_atk 245.502482227 4.89568354827e-54\n",
      "agc_WinningCleanSheet 235.069234474 9.0232772426e-52\n",
      "hgc_V 213.813298948 3.72419192972e-47\n",
      "agc_GS 204.620335544 3.69197451017e-45\n",
      "hgc_GS 203.094392921 7.91795309168e-45\n",
      "lh_rank_def 202.769027174 9.31676623281e-45\n",
      "agc_D 193.229738793 1.09823517946e-42\n",
      "hgc_LosingFS 184.601365143 8.20961674835e-41\n",
      "hgc_FailedScore 164.124599007 2.29507114745e-36\n",
      "la_rank_atk 159.636396022 2.16469666612e-35\n",
      "al_V 158.196067691 4.44795486235e-35\n",
      "agc_CleanSheet 158.163137976 4.52179603076e-35\n",
      "la_rank_def 157.718551424 5.64744111526e-35\n",
      "ag_J1GF 154.926236368 2.28136734921e-34\n",
      "agc_LosingFS 153.011402108 5.94286956212e-34\n",
      "hg_CleanSheet 138.041559081 1.05841578658e-30\n",
      "hlc_GF 128.237159693 1.42447419135e-28\n",
      "hl_V 125.465023741 5.69660699368e-28\n",
      "al_GS 122.63482112 2.34523814385e-27\n",
      "hgc_WinningCleanSheet 117.7718509 2.66788751901e-26\n",
      "ag_Over4 116.387909331 5.32950174385e-26\n",
      "agc_FailedScore 111.551272048 5.98341395761e-25\n",
      "hg_J1GF 104.726740197 1.81500285437e-23\n",
      "al_D 103.307693384 3.68994091907e-23\n",
      "al_WinningCleanSheet 101.843594416 7.67263368343e-23\n"
     ]
    }
   ],
   "source": [
    "selected_ft=[]\n",
    "for key,value in sorted_x:\n",
    "    selected_ft.append(ft[key])\n",
    "    print ft[key],value,pvalue[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B365A',\n",
       " u'ag_GF',\n",
       " u'hg_GF',\n",
       " 'B365H',\n",
       " u'gh_rank_atk',\n",
       " u'ag_V',\n",
       " u'hgc_GF',\n",
       " u'ga_rank_atk',\n",
       " u'agc_GF',\n",
       " u'gh_rank_def',\n",
       " u'hg_GS',\n",
       " u'hg_V',\n",
       " u'hg_D',\n",
       " u'ag_D',\n",
       " u'ga_rank_def',\n",
       " u'ag_WinningCleanSheet',\n",
       " u'ag_GS',\n",
       " u'hg_LosingFS',\n",
       " u'agc_V',\n",
       " u'hg_FailedScore',\n",
       " u'ag_LosingFS',\n",
       " u'al_GF',\n",
       " u'hgc_D',\n",
       " u'hg_WinningCleanSheet',\n",
       " u'hl_GF',\n",
       " u'ag_CleanSheet',\n",
       " u'ag_FailedScore',\n",
       " u'lh_rank_atk',\n",
       " u'agc_WinningCleanSheet',\n",
       " u'hgc_V',\n",
       " u'agc_GS',\n",
       " u'hgc_GS',\n",
       " u'lh_rank_def',\n",
       " u'agc_D',\n",
       " u'hgc_LosingFS',\n",
       " u'hgc_FailedScore',\n",
       " u'la_rank_atk',\n",
       " u'al_V',\n",
       " u'agc_CleanSheet',\n",
       " u'la_rank_def',\n",
       " u'ag_J1GF',\n",
       " u'agc_LosingFS',\n",
       " u'hg_CleanSheet',\n",
       " u'hlc_GF',\n",
       " u'hl_V',\n",
       " u'al_GS',\n",
       " u'hgc_WinningCleanSheet',\n",
       " u'ag_Over4',\n",
       " u'agc_FailedScore',\n",
       " u'hg_J1GF',\n",
       " u'al_D',\n",
       " u'al_WinningCleanSheet']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ft\n",
    "C= [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "ft_train = featured[featured['season']<=5]\n",
    "ft_val = featured[featured['season']==6]\n",
    "ft_test = featured[featured['season']==7]\n",
    "logreg_select=logreg_validation(C,solver,ft_train,ft_val,selected_ft,out)\n",
    "n = range(100,1000,50)\n",
    "rf_select= rf_validation(n,ft_train,ft_val,selected_ft,out)\n",
    "lr= [0.0001, 0.001, 0.01, 0.1]\n",
    "gb_select= gb_validation(lr,n,train,val,ft,out)\n",
    "nb_select= nb_validation(train,val,ft,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"\\t\\tF1Score\\t\",\"      F1 macro\\t\",\"    F1 micro\"\n",
    "print \"Naive      \", naive,f1_score(test[out],ynaive,average='macro'),f1_score(test[out],ynaive,average='micro')\n",
    "print \"LogReg     \", f1_score(test[out],logreg.predict(test[ft]),average='weighted'),f1_score(test[out],logreg.predict(test[ft]),average='macro'),f1_score(test[out],logreg.predict(test[ft]),average='micro')\n",
    "print \"Naive Bayes\", f1_score(test[out],nb.predict(test[ft]),average='weighted'),f1_score(test[out],nb.predict(test[ft]),average='macro'),f1_score(test[out],nb.predict(test[ft]),average='micro')\n",
    "print \"Random F.  \", f1_score(test[out],rf.predict(test[ft]),average='weighted'),f1_score(test[out],rf.predict(test[ft]),average='macro'),f1_score(test[out],rf.predict(test[ft]),average='micro')\n",
    "print \"G. Boost.  \", f1_score(test[out],gb.predict(test[ft]),average='weighted'),f1_score(test[out],gb.predict(test[ft]),average='macro'),f1_score(test[out],gb.predict(test[ft]),average='micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
